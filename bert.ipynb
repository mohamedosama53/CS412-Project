{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "turkish_stopwords = stopwords.words('turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification_df = pd.read_csv(\"/Users/Osama/Downloads/CS412PROJ/train-classification.csv\",)\n",
    "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
    "\n",
    "# Unifying labels\n",
    "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
    "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\n\\n# Load the annotated user file\\nannotated_file_path = \"/Users/Osama/Downloads/CS412PROJ/annotated_users_CS412-2753ef4cf74e.csv\"\\nannotated_users_df = pd.read_csv(annotated_file_path)\\n\\n# Extract user_id and category columns\\nannotated_users_df = annotated_users_df.rename(columns={\\'Unnamed: 0\\': \\'user_id\\', \\'influencerCategory\\': \\'category\\'})\\n\\nannotated_users_df[\"category\"] = annotated_users_df[\"category\"].str.lower()\\n\\n# Add the new users to the username2_category dictionary without updating existing ones\\nnew_users_dict = annotated_users_df.set_index(\"user_id\").to_dict()[\"category\"]\\n\\n# Only add the new users that are not already in username2_category\\nfor user_id, category in new_users_dict.items():\\n    if user_id not in username2_category:\\n        username2_category[user_id] = category\\n\\n# Optionally, verify the addition\\nprint(f\"Number of new users added: {len(new_users_dict)}\")\\nprint(f\"Updated number of users in the training set: {len(username2_category)}\")'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "\n",
    "# Load the annotated user file\n",
    "annotated_file_path = \"/Users/Osama/Downloads/CS412PROJ/annotated_users_CS412-2753ef4cf74e.csv\"\n",
    "annotated_users_df = pd.read_csv(annotated_file_path)\n",
    "\n",
    "# Extract user_id and category columns\n",
    "annotated_users_df = annotated_users_df.rename(columns={'Unnamed: 0': 'user_id', 'influencerCategory': 'category'})\n",
    "\n",
    "annotated_users_df[\"category\"] = annotated_users_df[\"category\"].str.lower()\n",
    "\n",
    "# Add the new users to the username2_category dictionary without updating existing ones\n",
    "new_users_dict = annotated_users_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
    "\n",
    "# Only add the new users that are not already in username2_category\n",
    "for user_id, category in new_users_dict.items():\n",
    "    if user_id not in username2_category:\n",
    "        username2_category[user_id] = category\n",
    "\n",
    "# Optionally, verify the addition\n",
    "print(f\"Number of new users added: {len(new_users_dict)}\")\n",
    "print(f\"Updated number of users in the training set: {len(username2_category)}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health and lifestyle</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom and children</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id\n",
       "category                     \n",
       "art                       191\n",
       "entertainment             323\n",
       "fashion                   299\n",
       "food                      511\n",
       "gaming                     13\n",
       "health and lifestyle      503\n",
       "mom and children          149\n",
       "sports                    113\n",
       "tech                      346\n",
       "travel                    294"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_df.groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tech'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username2_category[\"kod8net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_classification_df = pd.read_csv(\"/Users/Osama/Downloads/CS412PROJ/train-classification.csv\",)\\ntrain_classification_df = train_classification_df.rename(columns={\\'Unnamed: 0\\': \\'user_id\\', \\'label\\': \\'category\\'})\\n\\n# Unifying labels\\ntrain_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\\nusername2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\\n\\n\\n\\n\\n# Load the additional CSV file\\nadditional_data_path = \"/Users/Osama/Downloads/CS412PROJ/annotated_users_CS412-2753ef4cf74e.csv\"\\nadditional_data_df = pd.read_csv(additional_data_path)\\n\\n# Extract and rename the relevant columns\\nadditional_data_df = additional_data_df[[\\'Unnamed: 0\\', \\'influencerCategory\\']].rename(columns={\\n    \\'Unnamed: 0\\': \\'user_id\\', \\n    \\'influencerCategory\\': \\'category\\'\\n})\\n\\nadditional_data_df = additional_data_df.dropna()\\n\\n\\n\\n# Convert the \\'category\\' column to string type and apply .lower(), handling any NaN or unexpected values\\nadditional_data_df[\\'category\\'] = additional_data_df[\\'category\\'].astype(str).fillna(\\'\\').apply(str.lower)\\n\\n# Append the new data to the original train_classification_df\\ntrain_classification_df = pd.concat([train_classification_df, additional_data_df], ignore_index=True)\\n\\n# Update the username2_category dictionary with the new data\\nusername2_category.update(additional_data_df.set_index(\"user_id\").to_dict()[\"category\"])\\n\\n# Check the updated data by viewing the first few rows\\nprint(train_classification_df.head())\\n\\n# Re-check the category distribution\\ntrain_classification_df.groupby(\"category\").count()'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_classification_df = pd.read_csv(\"/Users/Osama/Downloads/CS412PROJ/train-classification.csv\",)\n",
    "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
    "\n",
    "# Unifying labels\n",
    "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
    "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the additional CSV file\n",
    "additional_data_path = \"/Users/Osama/Downloads/CS412PROJ/annotated_users_CS412-2753ef4cf74e.csv\"\n",
    "additional_data_df = pd.read_csv(additional_data_path)\n",
    "\n",
    "# Extract and rename the relevant columns\n",
    "additional_data_df = additional_data_df[['Unnamed: 0', 'influencerCategory']].rename(columns={\n",
    "    'Unnamed: 0': 'user_id', \n",
    "    'influencerCategory': 'category'\n",
    "})\n",
    "\n",
    "additional_data_df = additional_data_df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Convert the 'category' column to string type and apply .lower(), handling any NaN or unexpected values\n",
    "additional_data_df['category'] = additional_data_df['category'].astype(str).fillna('').apply(str.lower)\n",
    "\n",
    "# Append the new data to the original train_classification_df\n",
    "train_classification_df = pd.concat([train_classification_df, additional_data_df], ignore_index=True)\n",
    "\n",
    "# Update the username2_category dictionary with the new data\n",
    "username2_category.update(additional_data_df.set_index(\"user_id\").to_dict()[\"category\"])\n",
    "\n",
    "# Check the updated data by viewing the first few rows\n",
    "print(train_classification_df.head())\n",
    "\n",
    "# Re-check the category distribution\n",
    "train_classification_df.groupby(\"category\").count()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/Users/Osama/Downloads/CS412PROJ/training-dataset.jsonl.gz\"\n",
    "\n",
    "username2posts_train = dict()\n",
    "username2profile_train = dict()\n",
    "\n",
    "username2posts_test = dict()\n",
    "username2profile_test = dict()\n",
    "\n",
    "\n",
    "with gzip.open(train_data_path, \"rt\") as fh:\n",
    "  for line in fh:\n",
    "    sample = json.loads(line)\n",
    "\n",
    "    profile = sample[\"profile\"]\n",
    "    username = profile[\"username\"]\n",
    "    if username in username2_category:\n",
    "      # train data info\n",
    "      username2posts_train[username] = sample[\"posts\"]\n",
    "      username2profile_train[username] = profile\n",
    "\n",
    "\n",
    "    else:\n",
    "      # it is test data info\n",
    "      username2posts_test[username] = sample[\"posts\"]\n",
    "      username2profile_test[username] = profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2741, 44)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
    "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n",
    "\n",
    "train_profile_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>biography</th>\n",
       "      <th>category_name</th>\n",
       "      <th>post_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>is_business_account</th>\n",
       "      <th>is_private</th>\n",
       "      <th>...</th>\n",
       "      <th>business_category_name</th>\n",
       "      <th>overall_category_name</th>\n",
       "      <th>category_enum</th>\n",
       "      <th>is_verified_by_mv4b</th>\n",
       "      <th>is_regulated_c18</th>\n",
       "      <th>profile_pic_url</th>\n",
       "      <th>should_show_category</th>\n",
       "      <th>should_show_public_contacts</th>\n",
       "      <th>show_account_transparency_details</th>\n",
       "      <th>profile_picture_base64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyazyakaliyiz</td>\n",
       "      <td>8634457436</td>\n",
       "      <td>Selam Beyaz Yakalı</td>\n",
       "      <td>Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀</td>\n",
       "      <td>Personal blog</td>\n",
       "      <td>None</td>\n",
       "      <td>1265</td>\n",
       "      <td>665</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PERSONAL_BLOG</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>totalenergies_istasyonlari</td>\n",
       "      <td>7066643793</td>\n",
       "      <td>TotalEnergies İstasyonları</td>\n",
       "      <td>TotalEnergies İstasyonları resmi Instagram hes...</td>\n",
       "      <td>Energy Company</td>\n",
       "      <td>None</td>\n",
       "      <td>28025</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ENERGY_COMPANY</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     username          id                    full_name  \\\n",
       "0              beyazyakaliyiz  8634457436           Selam Beyaz Yakalı   \n",
       "1  totalenergies_istasyonlari  7066643793  TotalEnergies İstasyonları   \n",
       "\n",
       "                                           biography   category_name  \\\n",
       "0        Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀   Personal blog   \n",
       "1  TotalEnergies İstasyonları resmi Instagram hes...  Energy Company   \n",
       "\n",
       "  post_count follower_count following_count is_business_account is_private  \\\n",
       "0       None           1265             665                True      False   \n",
       "1       None          28025               4                True      False   \n",
       "\n",
       "   ... business_category_name overall_category_name   category_enum  \\\n",
       "0  ...                   None                  None   PERSONAL_BLOG   \n",
       "1  ...                   None                  None  ENERGY_COMPANY   \n",
       "\n",
       "  is_verified_by_mv4b is_regulated_c18  \\\n",
       "0               False            False   \n",
       "1               False            False   \n",
       "\n",
       "                                     profile_pic_url should_show_category  \\\n",
       "0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n",
       "1  https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....                 True   \n",
       "\n",
       "  should_show_public_contacts show_account_transparency_details  \\\n",
       "0                        True                              True   \n",
       "1                        True                              True   \n",
       "\n",
       "                              profile_picture_base64  \n",
       "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_profile_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_array_api.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\fixes.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     pd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\__init__.py:155\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     ExcelFile,\n\u001b[0;32m    158\u001b[0m     ExcelWriter,\n\u001b[0;32m    159\u001b[0m     read_excel,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# parsers\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     read_csv,\n\u001b[0;32m    162\u001b[0m     read_fwf,\n\u001b[0;32m    163\u001b[0m     read_table,\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# pickle\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     read_pickle,\n\u001b[0;32m    166\u001b[0m     to_pickle,\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# pytables\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     HDFStore,\n\u001b[0;32m    169\u001b[0m     read_hdf,\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# sql\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     read_sql,\n\u001b[0;32m    172\u001b[0m     read_sql_query,\n\u001b[0;32m    173\u001b[0m     read_sql_table,\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     read_clipboard,\n\u001b[0;32m    176\u001b[0m     read_parquet,\n\u001b[0;32m    177\u001b[0m     read_orc,\n\u001b[0;32m    178\u001b[0m     read_feather,\n\u001b[0;32m    179\u001b[0m     read_gbq,\n\u001b[0;32m    180\u001b[0m     read_html,\n\u001b[0;32m    181\u001b[0m     read_xml,\n\u001b[0;32m    182\u001b[0m     read_json,\n\u001b[0;32m    183\u001b[0m     read_stata,\n\u001b[0;32m    184\u001b[0m     read_sas,\n\u001b[0;32m    185\u001b[0m     read_spss,\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_normalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_normalize\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\api.py:31\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     HDFStore,\n\u001b[0;32m     28\u001b[0m     read_hdf,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_sas\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_spss\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     read_sql,\n\u001b[0;32m     34\u001b[0m     read_sql_query,\n\u001b[0;32m     35\u001b[0m     read_sql_table,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_stata\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from zemberek import TurkishMorphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the Zemberek morphology object\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "\n",
    "def preprocess_text_zemberek(text: str):\n",
    "    # Tokenizing the input text\n",
    "    tokens = text.split()\n",
    "    stems = []\n",
    "\n",
    "    # Analyze each token\n",
    "    for token in tokens:\n",
    "        analysis = morphology.analyze(token)\n",
    "        \n",
    "        # Extract the stem from the analysis results\n",
    "        if analysis.analysis_results:\n",
    "            # Take the stem of the first analysis result\n",
    "            stem = analysis.analysis_results[0].get_stem()  \n",
    "        else:\n",
    "            # If no analysis is found, use the original token\n",
    "            stem = token\n",
    "            \n",
    "        stems.append(stem)\n",
    "\n",
    "    # Join the stems to create the processed text\n",
    "    return \" \".join(stems)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# to keep the label order\n",
    "train_usernames = []\n",
    "\n",
    "for username, posts in username2posts_train.items():\n",
    "    train_usernames.append(username)\n",
    "\n",
    "    # Aggregating the posts per user\n",
    "    cleaned_captions = []\n",
    "    for post in posts:\n",
    "        post_caption = post.get(\"caption\", \"\")\n",
    "        if post_caption is None:\n",
    "            continue\n",
    "\n",
    "        post_caption = preprocess_text_zemberek(post_caption)\n",
    "\n",
    "        if post_caption != \"\":\n",
    "            cleaned_captions.append(post_caption)\n",
    "\n",
    "    # Joining the posts of each user with a \\n\n",
    "    user_post_captions = \"\\n\".join(cleaned_captions)\n",
    "    corpus.append(user_post_captions)\n",
    "\n",
    "\n",
    "custom_stopwords = list(set(turkish_stopwords).union({\n",
    "    'the'\n",
    "}))\n",
    "vectorizer = TfidfVectorizer(stop_words=turkish_stopwords, max_features=15000, min_df=10, sublinear_tf=True, smooth_idf=False, ngram_range=(1, 3))\n",
    "\n",
    "# Fit the vectorizer\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the data into vectors\n",
    "x_post_train = vectorizer.transform(corpus)\n",
    "y_train = [username2_category.get(uname, \"NA\") for uname in train_usernames]\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Perform chi-squared feature selection\n",
    "chi2_selector = SelectKBest(chi2, k=5000)  # Select the top 5000 features\n",
    "x_post_train_selected = chi2_selector.fit_transform(x_post_train, y_train)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
    "selected_feature_names = np.array(feature_names)[selected_feature_indices]\n",
    "\n",
    "# Convert the selected features into a DataFrame for analysis\n",
    "df_tfidf = pd.DataFrame(x_post_train_selected.toarray(), columns=selected_feature_names)\n",
    "\n",
    "# Show the most frequent selected words\n",
    "print(df_tfidf.sum().sort_values(ascending=False).head(30))\n",
    "\n",
    "######################################\n",
    "\n",
    "\n",
    "test_usernames = []\n",
    "test_corpus = []\n",
    "for username, posts in username2posts_test.items():\n",
    "    test_usernames.append(username)\n",
    "    # Aggregating the posts per user\n",
    "    cleaned_captions = []\n",
    "    for post in posts:\n",
    "        post_caption = post.get(\"caption\", \"\")\n",
    "        if post_caption is None:\n",
    "            continue\n",
    "\n",
    "        post_caption = preprocess_text_zemberek(post_caption)\n",
    "\n",
    "        if post_caption != \"\":\n",
    "            cleaned_captions.append(post_caption)\n",
    "\n",
    "    user_post_captions = \"\\n\".join(cleaned_captions)\n",
    "    test_corpus.append(user_post_captions)\n",
    "\n",
    "\n",
    "# Just transforming! No Fitting!!!!!\n",
    "x_post_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "# Transform the test set using the same feature selection\n",
    "x_post_test_selected = chi2_selector.transform(x_post_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Making sure everything is fine\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43my_train\u001b[49m\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Making sure everything is fine\n",
    "assert y_train.count(\"NA\") == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ab', 'abant', 'abd', ..., 'şıklığın', 'şımartın', 'şırnak'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abant</th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abi</th>\n",
       "      <th>abiye</th>\n",
       "      <th>accessories</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accompanied</th>\n",
       "      <th>accompanied by</th>\n",
       "      <th>activities</th>\n",
       "      <th>acı</th>\n",
       "      <th>...</th>\n",
       "      <th>şubelerinde</th>\n",
       "      <th>şubemiz</th>\n",
       "      <th>şölen</th>\n",
       "      <th>şöleni</th>\n",
       "      <th>şükür</th>\n",
       "      <th>şık</th>\n",
       "      <th>şık bir</th>\n",
       "      <th>şıklık</th>\n",
       "      <th>şıklığı</th>\n",
       "      <th>şıklığın</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abant  abdullah  abi  abiye  accessories  accommodation  accompanied  \\\n",
       "0    0.0       0.0  0.0    0.0          0.0            0.0          0.0   \n",
       "1    0.0       0.0  0.0    0.0          0.0            0.0          0.0   \n",
       "\n",
       "   accompanied by  activities  acı  ...  şubelerinde  şubemiz  şölen  şöleni  \\\n",
       "0             0.0         0.0  0.0  ...          0.0      0.0    0.0     0.0   \n",
       "1             0.0         0.0  0.0  ...          0.0      0.0    0.0     0.0   \n",
       "\n",
       "   şükür      şık  şık bir  şıklık  şıklığı  şıklığın  \n",
       "0    0.0  0.04435      0.0     0.0      0.0       0.0  \n",
       "1    0.0  0.00000      0.0     0.0      0.0       0.0  \n",
       "\n",
       "[2 rows x 5000 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(x_post_train_selected.toarray(), columns=selected_feature_names)\n",
    "df_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2741, 5000)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_tfidf: (2741, 5000)\n",
      "Length of y_train: 2741\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of df_tfidf:\", df_tfidf.shape)\n",
    "print(\"Length of y_train:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_samples' parameter of resample must be an int in the range [1, inf) or None. Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m minority_class \u001b[38;5;241m=\u001b[39m train_data[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminority_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Randomly duplicate samples from the minority class\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m minority_oversampled \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminority_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Sample with replacement\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmajority_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Make it equal size to the majority class\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Combine the oversampled minority class with the majority class\u001b[39;00m\n\u001b[0;32m     19\u001b[0m train_data_resampled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([majority_class, minority_oversampled])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'n_samples' parameter of resample must be an int in the range [1, inf) or None. Got 0 instead."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train,random_state=42)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2192, 5000)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 5000)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_log_transformed = np.log1p(x_train)  # Use log(1 + x) to avoid log(0) issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights with Log10 scaling: {'art': 0.5955211694024377, 'entertainment': 0.5394838964231858, 'fashion': 0.5470194853204887, 'food': 0.4981500114024804, 'gaming': 1.301029995663981, 'health and lifestyle': 0.49958412562650956, 'mom and children': 0.6268371758695794, 'sports': 0.6657464410787219, 'tech': 0.532667665109185, 'travel': 0.5487105689237657}\n",
      "Class Weights: {'art': 1.4326797385620915, 'entertainment': 0.8496124031007752, 'fashion': 0.9171548117154812, 'food': 0.5359413202933986, 'gaming': 21.92, 'health and lifestyle': 0.545273631840796, 'mom and children': 1.842016806722689, 'sports': 2.4355555555555557, 'tech': 0.7913357400722022, 'travel': 0.9327659574468085}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-24 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-24 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-24 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-24 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-24 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-24 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=1,\n",
       "          class_weight={&#x27;art&#x27;: 0.5955211694024377,\n",
       "                        &#x27;entertainment&#x27;: 0.5394838964231858,\n",
       "                        &#x27;fashion&#x27;: 0.5470194853204887,\n",
       "                        &#x27;food&#x27;: 0.4981500114024804, &#x27;gaming&#x27;: 1.301029995663981,\n",
       "                        &#x27;health and lifestyle&#x27;: 0.49958412562650956,\n",
       "                        &#x27;mom and children&#x27;: 0.6268371758695794,\n",
       "                        &#x27;sports&#x27;: 0.6657464410787219, &#x27;tech&#x27;: 0.532667665109185,\n",
       "                        &#x27;travel&#x27;: 0.5487105689237657},\n",
       "          max_iter=2000, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=1,\n",
       "          class_weight={&#x27;art&#x27;: 0.5955211694024377,\n",
       "                        &#x27;entertainment&#x27;: 0.5394838964231858,\n",
       "                        &#x27;fashion&#x27;: 0.5470194853204887,\n",
       "                        &#x27;food&#x27;: 0.4981500114024804, &#x27;gaming&#x27;: 1.301029995663981,\n",
       "                        &#x27;health and lifestyle&#x27;: 0.49958412562650956,\n",
       "                        &#x27;mom and children&#x27;: 0.6268371758695794,\n",
       "                        &#x27;sports&#x27;: 0.6657464410787219, &#x27;tech&#x27;: 0.532667665109185,\n",
       "                        &#x27;travel&#x27;: 0.5487105689237657},\n",
       "          max_iter=2000, random_state=123)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=1,\n",
       "          class_weight={'art': 0.5955211694024377,\n",
       "                        'entertainment': 0.5394838964231858,\n",
       "                        'fashion': 0.5470194853204887,\n",
       "                        'food': 0.4981500114024804, 'gaming': 1.301029995663981,\n",
       "                        'health and lifestyle': 0.49958412562650956,\n",
       "                        'mom and children': 0.6268371758695794,\n",
       "                        'sports': 0.6657464410787219, 'tech': 0.532667665109185,\n",
       "                        'travel': 0.5487105689237657},\n",
       "          max_iter=2000, random_state=123)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Count the number of users in each class\n",
    "class_counts = Counter(y_train)\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = len(y_train)\n",
    "\n",
    "# Calculate class weights using log10\n",
    "'''log_class_weights = {\n",
    "    cls: np.log10(1 + total_samples / count)  # Logarithmic scaling of class weight\n",
    "    for cls, count in class_counts.items()\n",
    "}\n",
    "'''\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "log_class_weights = {cls: 1 / (np.log(cnt) / np.log(20)) for cls, cnt in zip(unique_classes, class_counts)}\n",
    "print(\"Class Weights with Log10 scaling:\", log_class_weights)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize SVM model with class weights\n",
    "svm_model = LinearSVC(class_weight=log_class_weights,max_iter=2000,C=1,random_state=123)\n",
    "\n",
    "\n",
    "\n",
    "#svm_model = LinearSVC(class_weight=class_weight_dict, max_iter=2000)\n",
    "#non_linear_svm = SVC(kernel='rbf', class_weight=log_class_weights,max_iter=2000,random_state=42)\n",
    "# Train the model\n",
    "svm_model.fit(x_train_log_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import classification_report, confusion_matrix\\nimport numpy as np\\n\\n# Calculate class weights using log10\\nunique_classes, class_counts = np.unique(y_train, return_counts=True)\\nclass_weights = {cls: 1 / np.log10(1 + cnt) for cls, cnt in zip(unique_classes, class_counts)}\\n\\nprint(\"Class Weights (log10 adjusted):\", class_weights)\\n\\n# Create Logistic Regression model\\nlog_reg = LogisticRegression(\\n    multi_class=\\'multinomial\\',  # for multiclass classification\\n    solver=\\'lbfgs\\',            # efficient solver for multiclass problems\\n    class_weight=class_weights,  # handle class imbalance\\n    max_iter=1000               # allow sufficient iterations for convergence\\n)\\n\\n# Train the model\\nlog_reg.fit(x_train, y_train)\\n\\n# Predict on validation set\\ny_val_pred = log_reg.predict(x_val)\\n\\n# Evaluate the model\\nprint(\"Classification Report:\")\\nprint(classification_report(y_val, y_val_pred))\\n\\n# Confusion Matrix\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_val, y_val_pred))\\n'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights using log10\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "class_weights = {cls: 1 / np.log10(1 + cnt) for cls, cnt in zip(unique_classes, class_counts)}\n",
    "\n",
    "print(\"Class Weights (log10 adjusted):\", class_weights)\n",
    "\n",
    "# Create Logistic Regression model\n",
    "log_reg = LogisticRegression(\n",
    "    multi_class='multinomial',  # for multiclass classification\n",
    "    solver='lbfgs',            # efficient solver for multiclass problems\n",
    "    class_weight=class_weights,  # handle class imbalance\n",
    "    max_iter=1000               # allow sufficient iterations for convergence\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = log_reg.predict(x_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\nparam_grid = {'svc__C': [1, 5, 10, 50],\\n              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\\ngrid = GridSearchCV(svm_model, param_grid)\\n\\n%time grid.fit(Xtrain, ytrain)\\nprint(grid.best_params_)\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(svm_model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "print(grid.best_params_)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9516423357664233\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.97      0.90      0.93       153\n",
      "       entertainment       0.96      0.91      0.93       258\n",
      "             fashion       0.94      0.97      0.96       239\n",
      "                food       0.96      0.99      0.98       409\n",
      "              gaming       1.00      1.00      1.00        10\n",
      "health and lifestyle       0.94      0.92      0.93       402\n",
      "    mom and children       0.97      0.95      0.96       119\n",
      "              sports       1.00      0.94      0.97        90\n",
      "                tech       0.92      0.98      0.95       277\n",
      "              travel       0.95      0.96      0.96       235\n",
      "\n",
      "            accuracy                           0.95      2192\n",
      "           macro avg       0.96      0.95      0.96      2192\n",
      "        weighted avg       0.95      0.95      0.95      2192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Train Data\n",
    "y_train_pred = svm_model.predict(x_train)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7140255009107468\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.50      0.13      0.21        38\n",
      "       entertainment       0.68      0.42      0.51        65\n",
      "             fashion       0.64      0.77      0.70        60\n",
      "                food       0.83      0.94      0.88       102\n",
      "              gaming       0.00      0.00      0.00         3\n",
      "health and lifestyle       0.68      0.78      0.73       100\n",
      "    mom and children       0.70      0.53      0.60        30\n",
      "              sports       0.78      0.78      0.78        23\n",
      "                tech       0.71      0.91      0.80        69\n",
      "              travel       0.70      0.73      0.72        59\n",
      "\n",
      "            accuracy                           0.71       549\n",
      "           macro avg       0.62      0.60      0.59       549\n",
      "        weighted avg       0.70      0.71      0.69       549\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5  4 11  3  0  6  1  1  4  3]\n",
      " [ 2 27  5  5  0 12  1  0  7  6]\n",
      " [ 1  2 46  4  0  2  0  0  2  3]\n",
      " [ 0  3  0 96  0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0  1  0  1  1  0]\n",
      " [ 0  1  6  2  0 78  3  1  4  5]\n",
      " [ 0  2  4  1  0  7 16  0  0  0]\n",
      " [ 1  0  0  0  0  0  1 18  3  0]\n",
      " [ 0  0  0  1  0  3  0  1 63  1]\n",
      " [ 1  1  0  4  0  5  1  1  3 43]]\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = svm_model.predict(x_val)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi2_scores, p_values = chi2(x_train, y_train)\n",
    "feature_ranks = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"chi2\": chi2_scores\n",
    "}).sort_values(by=\"chi2\", ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(feature_ranks.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred, labels=np.unique(y_train))\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix, index=np.unique(y_train), columns=np.unique(y_train)\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Analyze specific misclassifications\n",
    "print(\"Misclassified samples:\")\n",
    "for i, (true, pred) in enumerate(zip(y_val, y_val_pred)):\n",
    "    if true != pred:\n",
    "        print(f\"Sample {i}: True={true}, Predicted={pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # This will generate unigrams, bigrams, and trigrams\n",
    "X_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Apply chi-squared test again on the new features\n",
    "chi2_scores, p_values = chi2(X_train_tfidf, y_train)\n",
    "\n",
    "# Create a dataframe of the features and their chi2 scores\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_ranks = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"chi2\": chi2_scores\n",
    "}).sort_values(by=\"chi2\", ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(feature_ranks.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that validation data is properly referenced\n",
    "# Assuming you have a list of usernames and captions for the validation set\n",
    "val_usernames = train_usernames[len(x_train):]  # Example placeholder\n",
    "val_corpus = corpus[len(x_train):]  # Example placeholder\n",
    "\n",
    "# Ensure y_val and y_val_pred are aligned with validation usernames\n",
    "y_val_aligned = y_val[:len(val_usernames)]\n",
    "y_val_pred_aligned = y_val_pred[:len(val_usernames)]\n",
    "\n",
    "# Recreate the DataFrame for validation data\n",
    "val_data = pd.DataFrame({\n",
    "    \"Username\": val_usernames,\n",
    "    \"True Label\": y_val_aligned,\n",
    "    \"Predicted Label\": y_val_pred_aligned,\n",
    "    \"Captions\": val_corpus\n",
    "})\n",
    "\n",
    "# Identify misclassified samples\n",
    "misclassified = val_data[val_data[\"True Label\"] != val_data[\"Predicted Label\"]]\n",
    "\n",
    "# Print misclassified samples with their captions\n",
    "print(\"Misclassified Samples with Captions:\")\n",
    "for _, row in misclassified.iterrows():\n",
    "    print(f\"Username: {row['Username']}\")\n",
    "    print(f\"True Label: {row['True Label']}\")\n",
    "    print(f\"Predicted Label: {row['Predicted Label']}\")\n",
    "    print(f\"Captions: {row['Captions']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test Data\n",
    "test_data_path = \"/Users/Osama/Downloads/CS412PROJ/test-classification-round1.dat\"\n",
    "\n",
    "with open(test_data_path, \"rt\") as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        print(line.strip())\n",
    "        if i >= 4:  # Stop after 5 lines\n",
    "            break\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "test_unames = []\n",
    "with open(test_data_path, \"rt\") as fh:\n",
    "  for line in fh:\n",
    "    test_unames.append(line.strip())\n",
    "\n",
    "print(test_unames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for uname in test_unames:\n",
    "  try:\n",
    "    index = test_usernames.index(uname)\n",
    "    x_test.append(x_post_test[index].toarray()[0])\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      index = train_usernames.index(uname)\n",
    "      x_test.append(x_post_train[index].toarray()[0])\n",
    "    except Exception as e:\n",
    "      print(uname)\n",
    "\n",
    "\n",
    "test_unames.remove(\"screenname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(np.array(x_test), columns=feature_names)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import gzip\n",
    "import json\n",
    "\n",
    "# Open the gzip-compressed JSONL file\n",
    "with gzip.open('training-dataset.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # Each line is a JSON object, so load it\n",
    "        data = json.loads(line)\n",
    "        print(data)  # You can process the data as needed\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
